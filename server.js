require('dotenv').config();
require('dotenv').config({ path: '.env.local' });

const express = require('express');
const WebSocket = require('ws');
const http = require('http');
const cors = require('cors');
const path = require('path');
const OpenAI = require('openai');
const { PollyClient, SynthesizeSpeechCommand } = require('@aws-sdk/client-polly');
const {
    TranscribeStreamingClient,
    StartStreamTranscriptionCommand
} = require('@aws-sdk/client-transcribe-streaming');

const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

// OpenAI ì„¤ì • (ëŒ€í™” ìƒì„±ìš©)
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

// AWS ì„¤ì •
const awsConfig = {
    region: process.env.AWS_REGION || 'ap-northeast-2',
    credentials: {
        accessKeyId: process.env.AWS_ACCESS_KEY_ID,
        secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
    },
};

const polly = new PollyClient(awsConfig);
const transcribeClient = new TranscribeStreamingClient(awsConfig);

// ë¯¸ë“¤ì›¨ì–´
app.use(cors());
app.use(express.json());
app.use(express.static('public'));

// í™œì„± ì—°ê²° ê´€ë¦¬
const activeConnections = new Map();

// ë¼ìš°íŠ¸
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/health', (req, res) => {
    res.json({ status: 'ok' });
});

// WebSocket ì—°ê²° ì²˜ë¦¬
wss.on('connection', (ws) => {
    const sessionId = Date.now().toString() + Math.random().toString(36).substr(2, 9);
    console.log(`New connection: ${sessionId}`);

    const connection = {
        ws: ws,
        transcribeStream: null,
        conversationHistory: [],
        isProcessing: false,
        audioChunks: []
    };

    activeConnections.set(sessionId, connection);

    ws.on('message', async (message) => {
        try {
            const data = JSON.parse(message.toString());

            switch (data.type) {
                case 'start-call':
                    await initializeTranscribeProcessing(sessionId);
                    ws.send(JSON.stringify({
                        type: 'call-ready',
                        sessionId: sessionId
                    }));
                    
                    // AI ì²« ì¸ì‚¬ ë©”ì‹œì§€ ìƒì„± ë° ì „ì†¡
                    setTimeout(async () => {
                        await sendWelcomeMessage(sessionId);
                    }, 1000); // 1ì´ˆ í›„ ì¸ì‚¬ë§
                    break;

                case 'audio-stream':
                    await handleAudioStream(sessionId, data.audioData);
                    break;

                case 'stop-tts':
                    // TTS ì¤‘ë‹¨ ì‹ í˜¸ ì²˜ë¦¬
                    console.log('TTS stop signal received');
                    break;

                case 'end-call':
                    await endTranscribeStream(sessionId);
                    // ì§„í–‰ ì¤‘ì¸ ì²˜ë¦¬ ì¤‘ë‹¨
                    const connection = activeConnections.get(sessionId);
                    if (connection) {
                        connection.isProcessing = false;
                        connection.audioChunks = []; // ëŒ€ê¸° ì¤‘ì¸ ì˜¤ë””ì˜¤ ì²­í¬ ì‚­ì œ
                        console.log('Call ended - stopped processing for session:', sessionId);
                    }
                    break;
            }

        } catch (error) {
            console.error('WebSocket message error:', error);
        }
    });

    ws.on('close', () => {
        console.log(`Connection closed: ${sessionId}`);
        const connection = activeConnections.get(sessionId);
        if (connection) {
            connection.isProcessing = false; // ëª¨ë“  ì²˜ë¦¬ ì¤‘ë‹¨
            connection.audioChunks = []; // ëŒ€ê¸° ì¤‘ì¸ ì˜¤ë””ì˜¤ ì‚­ì œ
            connection.transcribeStream = null; // ìŠ¤íŠ¸ë¦¼ ì°¸ì¡° ì œê±°
        }
        endTranscribeStream(sessionId);
        activeConnections.delete(sessionId);
    });
});

// AWS Transcribe ìŠ¤íŠ¸ë¦¼ ì‹œì‘
async function startTranscribeStream(sessionId) {
    const connection = activeConnections.get(sessionId);
    if (!connection) return;

    try {
        console.log(`Starting AWS Transcribe stream for session: ${sessionId}`);

        // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìƒì„± í•¨ìˆ˜
        const createAudioStream = async function* () {
            let streamActive = true;

            // ì—°ê²°ì´ í™œì„± ìƒíƒœì´ê³  ì²˜ë¦¬ ì¤‘ì¼ ë•Œë§Œ ìŠ¤íŠ¸ë¦¼ ìœ ì§€
            while (streamActive && connection.isProcessing) {
                if (connection.audioChunks.length > 0) {
                    const chunk = connection.audioChunks.shift();
                    yield { AudioEvent: { AudioChunk: chunk } };
                } else {
                    // ìƒˆ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¼ (100ms ëŒ€ê¸°)
                    await new Promise(resolve => setTimeout(resolve, 100));
                }

                // ì—°ê²° ìƒíƒœ ì¬í™•ì¸
                streamActive = activeConnections.has(sessionId) && connection.isProcessing;
            }
        };

        const command = new StartStreamTranscriptionCommand({
            LanguageCode: 'ko-KR',
            MediaEncoding: 'pcm',
            MediaSampleRateHertz: 16000,
            AudioStream: createAudioStream()
        });

        const response = await transcribeClient.send(command);
        connection.transcribeStream = response;

        console.log('AWS Transcribe stream started successfully');

        // ì‹¤ì‹œê°„ ì „ì‚¬ ê²°ê³¼ ì²˜ë¦¬
        if (response.TranscriptResultStream) {
            try {
                for await (const event of response.TranscriptResultStream) {
                    // ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ë‹¨
                    if (!connection.isProcessing || !activeConnections.has(sessionId)) {
                        console.log('Stream processing stopped for session:', sessionId);
                        break;
                    }

                    if (event.TranscriptEvent) {
                        const results = event.TranscriptEvent.Transcript.Results;
                        if (results && results.length > 0) {
                            const result = results[0];
                            if (!result.IsPartial && result.Alternatives && result.Alternatives.length > 0) {
                                const transcript = result.Alternatives[0].Transcript;
                                console.log('AWS Transcribe result:', transcript);
                                await handleTranscription(sessionId, transcript);
                            }
                        }
                    }
                }
            } catch (streamError) {
                console.log('Transcribe stream closed or interrupted:', streamError.message);
            }
        }

    } catch (error) {
        console.error('AWS Transcribe stream error:', error);
        // ì—ëŸ¬ ë°œìƒ ì‹œ ì—°ê²° ì •ë¦¬
        if (connection) {
            connection.transcribeStream = null;
        }
    }
}

// ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (AWS Transcribe ìŠ¤íŠ¸ë¦¬ë°ìš©)
async function handleAudioStream(sessionId, audioData) {
    const connection = activeConnections.get(sessionId);
    if (!connection || !audioData || !connection.isProcessing) return;

    // PCM ë°ì´í„°ë¥¼ Bufferë¡œ ë³€í™˜
    const audioBuffer = Buffer.from(new Int16Array(audioData).buffer);

    // ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ (ê°„ë‹¨í•œ ê²€ì¦)
    if (audioBuffer.length < 1000) { // ë„ˆë¬´ ì‘ì€ ì²­í¬ëŠ” ë¬´ì‹œ
        return;
    }

    // ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ìš© íì— ì¶”ê°€
    connection.audioChunks.push(audioBuffer);

    // AWS Transcribe ìŠ¤íŠ¸ë¦¬ë°ì€ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬ ë¶ˆí•„ìš”
    // ìŠ¤íŠ¸ë¦¼ì´ ìë™ìœ¼ë¡œ íì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ê°€ì„œ ì²˜ë¦¬í•¨

    console.log(`Audio chunk added to stream queue: ${audioBuffer.length} bytes`);
}

// AWS Transcribe ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘
async function initializeTranscribeProcessing(sessionId) {
    const connection = activeConnections.get(sessionId);
    if (!connection) return;

    // ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì‹œì‘
    connection.isProcessing = true;

    try {
        console.log('Initializing AWS Transcribe streaming for session:', sessionId);

        // AWS Transcribe ìŠ¤íŠ¸ë¦¼ ì‹œì‘
        await startTranscribeStream(sessionId);

    } catch (error) {
        console.error('Transcribe initialization error:', error);
        connection.isProcessing = false;
    }
}

// OpenAI Whisper ê´€ë ¨ ì½”ë“œ ì œê±°ë¨ - AWS Transcribe ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ëŒ€ì²´

// ì˜¤ë””ì˜¤ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
function isValidAudioData(audioBuffer) {
    if (!audioBuffer || audioBuffer.length === 0) {
        return false;
    }

    // ìµœì†Œ ê¸¸ì´ ì²´í¬ (0.5ì´ˆ ì´ìƒ)
    if (audioBuffer.length < 16000) { // 16kHz * 0.5ì´ˆ * 2 bytes
        console.log('Audio too short:', audioBuffer.length);
        return false;
    }

    // RMS ì—ë„ˆì§€ ê³„ì‚°
    let sum = 0;
    const samples = audioBuffer.length / 2; // 16-bit samples

    for (let i = 0; i < audioBuffer.length; i += 2) {
        const sample = audioBuffer.readInt16LE(i);
        sum += sample * sample;
    }

    const rms = Math.sqrt(sum / samples);
    const normalizedRMS = rms / 32768; // 16-bit ì •ê·œí™”

    console.log('Audio RMS:', normalizedRMS);

    // ìµœì†Œ ì—ë„ˆì§€ ì„ê³„ê°’ (ë°°ê²½ ì†ŒìŒë³´ë‹¤ ì¶©ë¶„íˆ ë†’ì•„ì•¼ í•¨)
    const minEnergyThreshold = 0.01;

    if (normalizedRMS < minEnergyThreshold) {
        console.log('Audio energy too low, likely silence or noise');
        return false;
    }

    return true;
}

// WAV ë³€í™˜ í•¨ìˆ˜ ì œê±°ë¨ - AWS Transcribeì—ì„œ PCM ì§ì ‘ ì²˜ë¦¬

// ì „ì‚¬ ê²°ê³¼ ì²˜ë¦¬
async function handleTranscription(sessionId, transcript) {
    const connection = activeConnections.get(sessionId);
    if (!connection) {
        console.log('Connection not found, skipping transcription handling for session:', sessionId);
        return;
    }

    // í†µí™”ê°€ ì¢…ë£Œëœ ê²½ìš° ì „ì‚¬ ê²°ê³¼ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
    if (!connection.isProcessing) {
        console.log('Call ended, skipping transcription handling for session:', sessionId);
        return;
    }

    console.log('Handling transcription:', transcript);

    try {
        // AI ì‘ë‹µ ìƒì„±
        const aiResponse = await generateAIResponse(transcript, connection.conversationHistory);
        if (!aiResponse) return;

        // ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        connection.conversationHistory.push(
            { role: 'user', content: transcript },
            { role: 'assistant', content: aiResponse }
        );

        // íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        if (connection.conversationHistory.length > 20) {
            connection.conversationHistory.splice(0, 2);
        }

        // TTS ìƒì„± ë° ì „ì†¡
        await generateAndStreamTTS(sessionId, aiResponse);

        // ëŒ€í™” ë¡œê·¸ ì „ì†¡
        connection.ws.send(JSON.stringify({
            type: 'conversation',
            user: transcript,
            assistant: aiResponse,
            timestamp: Date.now()
        }));

    } catch (error) {
        console.error('Transcription handling error:', error);
    }
}

// AI ì‘ë‹µ ìƒì„±
async function generateAIResponse(userMessage, history) {
    try {
        const completion = await openai.chat.completions.create({
            model: 'gpt-3.5-turbo',
            messages: [
                {
                    role: 'system',
                    content: 'ë‹¹ì‹ ì€ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”ë¥¼ í•˜ëŠ” ì¹œê·¼í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”. ì „í™” í†µí™”í•˜ë“¯ì´ ë°˜ì‘í•˜ê³ , ìƒëŒ€ë°©ì´ ë§ì„ ëŠì„ ìˆ˜ ìˆìŒì„ ê³ ë ¤í•´ í•µì‹¬ë¶€í„° ë§í•˜ì„¸ìš”.'
                },
                ...history,
                { role: 'user', content: userMessage }
            ],
            max_tokens: 150,
            temperature: 0.8
        });

        return completion.choices[0].message.content;

    } catch (error) {
        console.error('AI response error:', error);
        return null;
    }
}

// AWS Polly TTS ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë°
async function generateAndStreamTTS(sessionId, text) {
    const connection = activeConnections.get(sessionId);
    if (!connection) {
        console.log('Connection not found, skipping TTS for session:', sessionId);
        return;
    }

    // í†µí™”ê°€ ì¢…ë£Œë˜ì—ˆê±°ë‚˜ ì²˜ë¦¬ ì¤‘ë‹¨ëœ ê²½ìš° TTS ìƒì„±í•˜ì§€ ì•ŠìŒ
    if (!connection.isProcessing) {
        console.log('Call ended or processing stopped, skipping TTS for session:', sessionId);
        return;
    }

    try {
        console.log('Generating TTS for:', text.substring(0, 50) + '...');

        const command = new SynthesizeSpeechCommand({
            Text: text,
            OutputFormat: 'mp3',
            VoiceId: 'Seoyeon',
            Engine: 'neural',
            SampleRate: '22050'
        });

        const ttsResult = await polly.send(command);

        if (ttsResult.AudioStream) {
            const chunks = [];
            for await (const chunk of ttsResult.AudioStream) {
                chunks.push(chunk);
            }
            const audioBuffer = Buffer.concat(chunks);

            // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
            connection.ws.send(JSON.stringify({
                type: 'audio-response',
                audioData: audioBuffer.toString('base64'),
                contentType: 'audio/mp3'
            }));

            console.log('TTS audio sent to client');
        }

    } catch (error) {
        console.error('TTS error:', error);
    }
}

// Transcribe ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
async function endTranscribeStream(sessionId) {
    const connection = activeConnections.get(sessionId);
    if (!connection) return;

    // AWS Transcribe ìŠ¤íŠ¸ë¦¼ì€ isProcessing í”Œë˜ê·¸ë¡œ ì œì–´ë¨
    // ìŠ¤íŠ¸ë¦¼ ìì²´ëŠ” ì—°ê²° ì¢…ë£Œì‹œ ìë™ìœ¼ë¡œ ì •ë¦¬ë¨
    if (connection.transcribeStream) {
        try {
            // ì²˜ë¦¬ ìƒíƒœë¥¼ falseë¡œ ì„¤ì •í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ ë£¨í”„ ì¤‘ë‹¨
            connection.isProcessing = false;
            connection.transcribeStream = null;
            console.log(`Transcribe stream ended for session: ${sessionId}`);
        } catch (error) {
            console.error('Error ending transcribe stream:', error);
        }
    }
}

// AI í™˜ì˜ ë©”ì‹œì§€ ì „ì†¡
async function sendWelcomeMessage(sessionId) {
    const connection = activeConnections.get(sessionId);
    if (!connection || !connection.isProcessing) {
        console.log('Connection not found or not processing, skipping welcome message for session:', sessionId);
        return;
    }

    try {
        // í™˜ì˜ ë©”ì‹œì§€ ìƒì„±
        const welcomeMessages = [
            'ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” VibeMe AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?',
            'ë°˜ê°‘ìŠµë‹ˆë‹¤! ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.',
            'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.',
            'í™˜ì˜í•©ë‹ˆë‹¤! ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë– ì‹ ê°€ìš”? í¸í•˜ê²Œ ëŒ€í™”í•´ìš”.'
        ];
        
        const randomWelcome = welcomeMessages[Math.floor(Math.random() * welcomeMessages.length)];
        
        console.log('Sending welcome message:', randomWelcome);

        // ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        connection.conversationHistory.push({
            role: 'assistant', 
            content: randomWelcome
        });

        // TTS ìƒì„± ë° ì „ì†¡
        await generateAndStreamTTS(sessionId, randomWelcome);

        // ëŒ€í™” ë¡œê·¸ ì „ì†¡
        connection.ws.send(JSON.stringify({
            type: 'conversation',
            user: '',
            assistant: randomWelcome,
            timestamp: Date.now()
        }));

        console.log('Welcome message sent successfully for session:', sessionId);

    } catch (error) {
        console.error('Failed to send welcome message:', error);
    }
}

const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
    console.log(`ğŸ¤ VibeMe WebRTC + AWS Voice Chat running on port ${PORT}`);
    console.log(`ğŸ“ Real-time conversation with AWS Transcribe + Polly enabled`);
});
